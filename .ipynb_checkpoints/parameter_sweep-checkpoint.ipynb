{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training MC Agent with gamma = 0.897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   1%|          | 3/250 [00:00<00:10, 23.06episode/s, epsilon=0.996, total_reward=204]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: New best total reward: 736.2792217072638\n",
      "Episode 3: New best total reward: 2290.363211796524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  10%|█         | 26/250 [00:00<00:07, 29.73episode/s, epsilon=0.973, total_reward=1.56e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 23: New best total reward: 2569.4337863950677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  17%|█▋        | 42/250 [00:01<00:08, 24.11episode/s, epsilon=0.957, total_reward=1.99e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 39: New best total reward: 3012.692833861918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  73%|███████▎  | 182/250 [00:06<00:03, 21.19episode/s, epsilon=0.832, total_reward=2.32e+3] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 177: New best total reward: 3150.375148752567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes: 100%|██████████| 250/250 [00:08<00:00, 29.89episode/s, epsilon=0.779, total_reward=-1.07e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma: 0.897 -> Avg Reward: 761.86, Win Rate: 0.42\n",
      "\n",
      "Training MC Agent with gamma = 0.8976842105263159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   1%|          | 2/250 [00:00<00:19, 12.78episode/s, epsilon=0.997, total_reward=-275]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: New best total reward: 25.6818236758117\n",
      "Episode 2: New best total reward: 1248.0832611206856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   2%|▏         | 6/250 [00:00<00:09, 25.75episode/s, epsilon=0.994, total_reward=2.26e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 5: New best total reward: 2554.007423250189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   4%|▎         | 9/250 [00:00<00:09, 26.11episode/s, epsilon=0.99, total_reward=2.66e+3] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 10: New best total reward: 2663.997727461943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  16%|█▋        | 41/250 [00:01<00:08, 25.84episode/s, epsilon=0.957, total_reward=360]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 39: New best total reward: 3518.5249913521984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes: 100%|██████████| 250/250 [00:08<00:00, 30.91episode/s, epsilon=0.779, total_reward=1.32e+3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma: 0.8976842105263159 -> Avg Reward: 1125.10, Win Rate: 0.42\n",
      "\n",
      "Training MC Agent with gamma = 0.8983684210526316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   2%|▏         | 4/250 [00:00<00:07, 35.03episode/s, epsilon=0.994, total_reward=1.65e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: New best total reward: 2013.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   6%|▋         | 16/250 [00:00<00:08, 29.08episode/s, epsilon=0.984, total_reward=2.26e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 9: New best total reward: 2424.562036953633\n",
      "Episode 13: New best total reward: 2500.8495909626668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  12%|█▏        | 30/250 [00:01<00:07, 27.65episode/s, epsilon=0.969, total_reward=2.14e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 26: New best total reward: 2530.3892759482424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  88%|████████▊ | 221/250 [00:07<00:02, 12.96episode/s, epsilon=0.798, total_reward=1.12e+3] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 219: New best total reward: 3256.1673603709523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes: 100%|██████████| 250/250 [00:08<00:00, 28.41episode/s, epsilon=0.779, total_reward=1.58e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma: 0.8983684210526316 -> Avg Reward: 941.99, Win Rate: 0.44\n",
      "\n",
      "Training MC Agent with gamma = 0.8990526315789474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   1%|          | 3/250 [00:00<00:10, 22.95episode/s, epsilon=0.996, total_reward=3.28e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: New best total reward: 2341.37839742881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   2%|▏         | 6/250 [00:00<00:09, 25.37episode/s, epsilon=0.993, total_reward=1.83e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4: New best total reward: 3279.799607959942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  11%|█         | 27/250 [00:01<00:07, 28.58episode/s, epsilon=0.972, total_reward=1.03e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 22: New best total reward: 3622.521151236829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes: 100%|██████████| 250/250 [00:07<00:00, 32.96episode/s, epsilon=0.779, total_reward=1.26e+3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma: 0.8990526315789474 -> Avg Reward: 1021.90, Win Rate: 0.58\n",
      "\n",
      "Training MC Agent with gamma = 0.8997368421052632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   1%|          | 3/250 [00:00<00:10, 22.64episode/s, epsilon=0.995, total_reward=-246]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: New best total reward: 1405.5990634543398\n",
      "Episode 3: New best total reward: 1470.0643335943878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   4%|▎         | 9/250 [00:00<00:09, 26.10episode/s, epsilon=0.989, total_reward=2.8e+3] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 7: New best total reward: 1992.0411467782824\n",
      "Episode 10: New best total reward: 2149.1822200051884\n",
      "Episode 11: New best total reward: 2796.4871525756575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  39%|███▉      | 97/250 [00:03<00:05, 25.66episode/s, epsilon=0.905, total_reward=1.19e+3] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 93: New best total reward: 3450.356558995983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes: 100%|██████████| 250/250 [00:07<00:00, 31.92episode/s, epsilon=0.779, total_reward=1.7e+3]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma: 0.8997368421052632 -> Avg Reward: 808.40, Win Rate: 0.56\n",
      "\n",
      "Training MC Agent with gamma = 0.900421052631579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   1%|          | 2/250 [00:00<00:16, 14.73episode/s, epsilon=0.998, total_reward=-876]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: New best total reward: 832.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   1%|          | 2/250 [00:00<00:16, 14.73episode/s, epsilon=0.997, total_reward=3.09e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 3: New best total reward: 3085.518437862549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  62%|██████▏   | 154/250 [00:05<00:05, 19.06episode/s, epsilon=0.855, total_reward=3.3e+3]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 151: New best total reward: 3379.9365799685006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes: 100%|██████████| 250/250 [00:07<00:00, 32.17episode/s, epsilon=0.779, total_reward=-359]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma: 0.900421052631579 -> Avg Reward: 969.72, Win Rate: 0.54\n",
      "\n",
      "Training MC Agent with gamma = 0.9011052631578947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   0%|          | 0/250 [00:00<?, ?episode/s, epsilon=0.998, total_reward=946] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: New best total reward: -138.03362809113707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   1%|          | 2/250 [00:00<00:22, 11.06episode/s, epsilon=0.994, total_reward=2.02e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2: New best total reward: 945.700203120151\n",
      "Episode 5: New best total reward: 1102.0827117039712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   2%|▏         | 6/250 [00:00<00:11, 20.79episode/s, epsilon=0.992, total_reward=1.22e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 6: New best total reward: 2024.5981925879676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   4%|▎         | 9/250 [00:00<00:10, 22.79episode/s, epsilon=0.989, total_reward=641]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 9: New best total reward: 2154.2828212060263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  12%|█▏        | 30/250 [00:01<00:10, 20.23episode/s, epsilon=0.968, total_reward=2.29e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 28: New best total reward: 2200.751958538717\n",
      "Episode 29: New best total reward: 2644.904309716726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  28%|██▊       | 70/250 [00:02<00:06, 27.45episode/s, epsilon=0.93, total_reward=981]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 65: New best total reward: 2748.448025036404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  38%|███▊      | 94/250 [00:03<00:08, 19.45episode/s, epsilon=0.907, total_reward=1.25e+3] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 92: New best total reward: 3127.13899358429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes: 100%|██████████| 250/250 [00:08<00:00, 30.40episode/s, epsilon=0.779, total_reward=1.41e+3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma: 0.9011052631578947 -> Avg Reward: 836.34, Win Rate: 0.52\n",
      "\n",
      "Training MC Agent with gamma = 0.9017894736842106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   2%|▏         | 4/250 [00:00<00:06, 38.86episode/s, epsilon=0.992, total_reward=-1.63e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: New best total reward: 1901.1829423347942\n",
      "Episode 7: New best total reward: 1979.823271122711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   6%|▋         | 16/250 [00:00<00:08, 28.50episode/s, epsilon=0.981, total_reward=1.68e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 12: New best total reward: 2244.3900256867155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  16%|█▌        | 40/250 [00:01<00:06, 30.57episode/s, epsilon=0.96, total_reward=-565]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 34: New best total reward: 2859.724270023585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  28%|██▊       | 71/250 [00:02<00:07, 24.73episode/s, epsilon=0.929, total_reward=-479]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 69: New best total reward: 3475.234183578727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes: 100%|██████████| 250/250 [00:07<00:00, 32.13episode/s, epsilon=0.779, total_reward=361]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma: 0.9017894736842106 -> Avg Reward: 983.13, Win Rate: 0.62\n",
      "\n",
      "Training MC Agent with gamma = 0.9024736842105263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   2%|▏         | 4/250 [00:00<00:08, 29.53episode/s, epsilon=0.994, total_reward=1.33e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: New best total reward: 1235.0\n",
      "Episode 4: New best total reward: 1835.2242997130409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   8%|▊         | 21/250 [00:00<00:07, 30.44episode/s, epsilon=0.976, total_reward=-667]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 19: New best total reward: 1890.6015646611222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  13%|█▎        | 33/250 [00:01<00:09, 22.19episode/s, epsilon=0.967, total_reward=-582]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 30: New best total reward: 2067.6984832401877\n",
      "Episode 32: New best total reward: 2323.46135057924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  22%|██▏       | 54/250 [00:01<00:07, 26.41episode/s, epsilon=0.946, total_reward=2.87e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 53: New best total reward: 2770.922430957562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  24%|██▍       | 61/250 [00:02<00:07, 23.98episode/s, epsilon=0.94, total_reward=1.1e+3]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 55: New best total reward: 2867.3207517017536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  58%|█████▊    | 146/250 [00:05<00:04, 24.58episode/s, epsilon=0.862, total_reward=1.71e+3] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 139: New best total reward: 2967.4565020139826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  64%|██████▍   | 161/250 [00:06<00:05, 17.37episode/s, epsilon=0.849, total_reward=951]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 158: New best total reward: 4004.893207328675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes: 100%|██████████| 250/250 [00:08<00:00, 28.85episode/s, epsilon=0.779, total_reward=1.15e+3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma: 0.9024736842105263 -> Avg Reward: 813.36, Win Rate: 0.64\n",
      "\n",
      "Training MC Agent with gamma = 0.9031578947368422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   2%|▏         | 4/250 [00:00<00:07, 34.16episode/s, epsilon=0.994, total_reward=1.79e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: New best total reward: 1270.8180132206987\n",
      "Episode 2: New best total reward: 1641.095475617535\n",
      "Episode 5: New best total reward: 1890.8511654922431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  10%|▉         | 24/250 [00:00<00:08, 27.74episode/s, epsilon=0.972, total_reward=507]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 21: New best total reward: 2342.1513071368345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  44%|████▍     | 111/250 [00:03<00:05, 23.24episode/s, epsilon=0.893, total_reward=1.39e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 107: New best total reward: 3046.5256079882633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes: 100%|██████████| 250/250 [00:07<00:00, 32.48episode/s, epsilon=0.779, total_reward=-107]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma: 0.9031578947368422 -> Avg Reward: 731.01, Win Rate: 0.42\n",
      "\n",
      "Training MC Agent with gamma = 0.9038421052631579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   2%|▏         | 4/250 [00:00<00:07, 34.29episode/s, epsilon=0.994, total_reward=1.18e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: New best total reward: -413.0\n",
      "Episode 2: New best total reward: 1474.9020838696867\n",
      "Episode 3: New best total reward: 2140.604049374433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   5%|▍         | 12/250 [00:00<00:09, 26.27episode/s, epsilon=0.984, total_reward=145]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 10: New best total reward: 2372.7478338401233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  10%|█         | 25/250 [00:00<00:06, 32.95episode/s, epsilon=0.971, total_reward=851]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 19: New best total reward: 3152.790773837123\n",
      "Episode 28: New best total reward: 3603.7671268627664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes: 100%|██████████| 250/250 [00:07<00:00, 33.01episode/s, epsilon=0.779, total_reward=498]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma: 0.9038421052631579 -> Avg Reward: 673.97, Win Rate: 0.42\n",
      "\n",
      "Training MC Agent with gamma = 0.9045263157894737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   2%|▏         | 4/250 [00:00<00:08, 30.75episode/s, epsilon=0.995, total_reward=1.46e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: New best total reward: 1636.3907147842065\n",
      "Episode 3: New best total reward: 2353.483441496216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   6%|▋         | 16/250 [00:00<00:07, 30.65episode/s, epsilon=0.984, total_reward=920]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 10: New best total reward: 2431.9349586117974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  10%|█         | 25/250 [00:00<00:07, 29.61episode/s, epsilon=0.975, total_reward=1.52e+3] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 19: New best total reward: 2535.804742701309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  17%|█▋        | 42/250 [00:01<00:06, 30.31episode/s, epsilon=0.959, total_reward=1.72e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 36: New best total reward: 2625.667623685094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  23%|██▎       | 57/250 [00:02<00:07, 26.23episode/s, epsilon=0.944, total_reward=1.71e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 51: New best total reward: 2754.3479058585526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  34%|███▎      | 84/250 [00:02<00:05, 31.02episode/s, epsilon=0.918, total_reward=-678]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 77: New best total reward: 2825.3934579568167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes: 100%|██████████| 250/250 [00:07<00:00, 33.75episode/s, epsilon=0.779, total_reward=2.13e+3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma: 0.9045263157894737 -> Avg Reward: 859.45, Win Rate: 0.56\n",
      "\n",
      "Training MC Agent with gamma = 0.9052105263157895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   1%|          | 3/250 [00:00<00:09, 26.82episode/s, epsilon=0.994, total_reward=-452]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: New best total reward: -338.0\n",
      "Episode 2: New best total reward: 1512.1626329336973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   3%|▎         | 7/250 [00:00<00:07, 33.03episode/s, epsilon=0.993, total_reward=1.87e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 7: New best total reward: 1868.0110858940463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   4%|▍         | 11/250 [00:00<00:07, 31.90episode/s, epsilon=0.988, total_reward=850]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 9: New best total reward: 2342.7429994295203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   4%|▍         | 11/250 [00:00<00:07, 31.90episode/s, epsilon=0.986, total_reward=1.38e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 13: New best total reward: 2930.205680356701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  19%|█▉        | 47/250 [00:01<00:06, 29.71episode/s, epsilon=0.953, total_reward=-319]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 40: New best total reward: 3624.8998438393883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes: 100%|██████████| 250/250 [00:07<00:00, 33.08episode/s, epsilon=0.779, total_reward=-572]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma: 0.9052105263157895 -> Avg Reward: 1011.63, Win Rate: 0.56\n",
      "\n",
      "Training MC Agent with gamma = 0.9058947368421053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   1%|          | 3/250 [00:00<00:09, 24.85episode/s, epsilon=0.995, total_reward=2.1e+3] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: New best total reward: 1462.7707821684758\n",
      "Episode 5: New best total reward: 2095.726294475202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  11%|█         | 28/250 [00:00<00:06, 35.50episode/s, epsilon=0.971, total_reward=1229.0] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 20: New best total reward: 2799.0685072301867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  32%|███▏      | 80/250 [00:02<00:07, 23.96episode/s, epsilon=0.922, total_reward=2.07e+3] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 75: New best total reward: 2980.437496538202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  48%|████▊     | 121/250 [00:04<00:05, 22.74episode/s, epsilon=0.885, total_reward=1.24e+3] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 115: New best total reward: 3116.3413407739845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  80%|███████▉  | 199/250 [00:06<00:02, 21.20episode/s, epsilon=0.819, total_reward=-634]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 194: New best total reward: 3151.9879640850263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  88%|████████▊ | 220/250 [00:07<00:01, 17.83episode/s, epsilon=0.802, total_reward=-473]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 215: New best total reward: 3211.2877749735067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes: 100%|██████████| 250/250 [00:08<00:00, 28.34episode/s, epsilon=0.779, total_reward=1.59e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma: 0.9058947368421053 -> Avg Reward: 698.42, Win Rate: 0.48\n",
      "\n",
      "Training MC Agent with gamma = 0.906578947368421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   1%|          | 3/250 [00:00<00:10, 23.14episode/s, epsilon=0.995, total_reward=-346]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: New best total reward: 926.3907147842074\n",
      "Episode 2: New best total reward: 1030.9881711343387\n",
      "Episode 3: New best total reward: 3087.7435406616146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  84%|████████▍ | 210/250 [00:06<00:01, 20.02episode/s, epsilon=0.808, total_reward=1.37e+3] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 204: New best total reward: 3976.291322110634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes: 100%|██████████| 250/250 [00:07<00:00, 32.26episode/s, epsilon=0.779, total_reward=1.2e+3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma: 0.906578947368421 -> Avg Reward: 953.01, Win Rate: 0.52\n",
      "\n",
      "Training MC Agent with gamma = 0.9072631578947369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   1%|          | 2/250 [00:00<00:14, 17.40episode/s, epsilon=0.996, total_reward=-604]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: New best total reward: 2073.97904441189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   4%|▍         | 11/250 [00:00<00:07, 31.40episode/s, epsilon=0.988, total_reward=1.69e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 6: New best total reward: 2470.908714854774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  11%|█         | 28/250 [00:01<00:07, 31.65episode/s, epsilon=0.968, total_reward=1.89e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 25: New best total reward: 2714.010955520118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  35%|███▌      | 88/250 [00:02<00:05, 27.92episode/s, epsilon=0.915, total_reward=-292]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 81: New best total reward: 3063.669680137741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes: 100%|██████████| 250/250 [00:07<00:00, 33.18episode/s, epsilon=0.779, total_reward=1.96e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma: 0.9072631578947369 -> Avg Reward: 674.53, Win Rate: 0.52\n",
      "\n",
      "Training MC Agent with gamma = 0.9079473684210526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   1%|          | 2/250 [00:00<00:19, 12.95episode/s, epsilon=0.997, total_reward=1.76e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: New best total reward: 988.1241085011628\n",
      "Episode 2: New best total reward: 2225.412900409375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   6%|▌         | 15/250 [00:00<00:07, 30.74episode/s, epsilon=0.983, total_reward=-398]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 11: New best total reward: 2362.4190223660066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  34%|███▍      | 85/250 [00:02<00:05, 28.01episode/s, epsilon=0.916, total_reward=1.17e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 80: New best total reward: 2700.042332532793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  41%|████      | 103/250 [00:03<00:05, 26.40episode/s, epsilon=0.902, total_reward=-589]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 97: New best total reward: 2733.7673188690565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  46%|████▋     | 116/250 [00:03<00:05, 23.60episode/s, epsilon=0.89, total_reward=1.36e+3] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 110: New best total reward: 2915.1515263742276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  70%|███████   | 176/250 [00:06<00:04, 17.88episode/s, epsilon=0.837, total_reward=1.34e+3] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 171: New best total reward: 3276.97131446973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  90%|████████▉ | 224/250 [00:08<00:01, 18.02episode/s, epsilon=0.796, total_reward=-199]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 220: New best total reward: 3325.3309035833086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes: 100%|██████████| 250/250 [00:08<00:00, 28.40episode/s, epsilon=0.779, total_reward=-776]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma: 0.9079473684210526 -> Avg Reward: 740.92, Win Rate: 0.50\n",
      "\n",
      "Training MC Agent with gamma = 0.9086315789473685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   1%|          | 3/250 [00:00<00:10, 23.58episode/s, epsilon=0.995, total_reward=-182]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: New best total reward: -281.09841083496497\n",
      "Episode 2: New best total reward: 1718.362348272163\n",
      "Episode 3: New best total reward: 1742.2830091035457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   1%|          | 3/250 [00:00<00:10, 23.58episode/s, epsilon=0.993, total_reward=2.42e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 6: New best total reward: 2374.0483979409046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   4%|▍         | 10/250 [00:00<00:10, 23.62episode/s, epsilon=0.989, total_reward=1.31e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 7: New best total reward: 2419.6104061098736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   9%|▉         | 23/250 [00:00<00:09, 24.59episode/s, epsilon=0.975, total_reward=1.67e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 21: New best total reward: 2734.1821593536924\n",
      "Episode 23: New best total reward: 3134.9221138565154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  46%|████▋     | 116/250 [00:03<00:06, 22.12episode/s, epsilon=0.89, total_reward=441]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 112: New best total reward: 3788.6940392822903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes: 100%|██████████| 250/250 [00:07<00:00, 31.68episode/s, epsilon=0.779, total_reward=-722]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma: 0.9086315789473685 -> Avg Reward: 1072.62, Win Rate: 0.46\n",
      "\n",
      "Training MC Agent with gamma = 0.9093157894736842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   1%|          | 2/250 [00:00<00:15, 16.36episode/s, epsilon=0.997, total_reward=1546.0] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: New best total reward: 1863.3863828699466\n",
      "Episode 2: New best total reward: 1990.041968983102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   8%|▊         | 20/250 [00:00<00:07, 31.17episode/s, epsilon=0.978, total_reward=596]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 16: New best total reward: 2118.7626224971955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  18%|█▊        | 46/250 [00:01<00:07, 26.09episode/s, epsilon=0.952, total_reward=-70]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 43: New best total reward: 2414.463539682687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  25%|██▌       | 63/250 [00:02<00:07, 24.29episode/s, epsilon=0.935, total_reward=28.6]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 60: New best total reward: 2445.558934247603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  54%|█████▍    | 135/250 [00:04<00:04, 24.59episode/s, epsilon=0.871, total_reward=1.64e+3] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 128: New best total reward: 2714.958727770557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  60%|█████▉    | 149/250 [00:05<00:04, 22.46episode/s, epsilon=0.86, total_reward=1.18e+3] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 144: New best total reward: 4287.13295249648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes: 100%|██████████| 250/250 [00:08<00:00, 29.29episode/s, epsilon=0.779, total_reward=1.36e+3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma: 0.9093157894736842 -> Avg Reward: 614.13, Win Rate: 0.50\n",
      "\n",
      "Training MC Agent with gamma = 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   1%|          | 3/250 [00:00<00:09, 26.34episode/s, epsilon=0.996, total_reward=2.78]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: New best total reward: -869.0\n",
      "Episode 2: New best total reward: -857.0\n",
      "Episode 3: New best total reward: 793.4531071586948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   1%|          | 3/250 [00:00<00:09, 26.34episode/s, epsilon=0.995, total_reward=1.57e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 5: New best total reward: 1569.6184552407462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:   4%|▍         | 10/250 [00:00<00:09, 25.69episode/s, epsilon=0.99, total_reward=-474]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 6: New best total reward: 2062.1163803074905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  14%|█▍        | 35/250 [00:01<00:06, 32.42episode/s, epsilon=0.964, total_reward=1.63e+3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 30: New best total reward: 2309.6233217040485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  39%|███▉      | 98/250 [00:03<00:07, 21.33episode/s, epsilon=0.904, total_reward=-823]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 96: New best total reward: 2350.229124061768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  44%|████▍     | 110/250 [00:03<00:06, 20.43episode/s, epsilon=0.894, total_reward=815]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 106: New best total reward: 2508.3810718476625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes:  98%|█████████▊| 245/250 [00:08<00:00, 15.10episode/s, epsilon=0.781, total_reward=1.05e+3] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 242: New best total reward: 3186.3011618642604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes: 100%|██████████| 250/250 [00:08<00:00, 28.39episode/s, epsilon=0.779, total_reward=-826]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma: 0.91 -> Avg Reward: 896.38, Win Rate: 0.56\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYGAME_HIDE_SUPPORT_PROMPT'] = ''\n",
    "import pygame\n",
    "import random\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import torch  # Pour la sauvegarde/chargement du modèle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Fonction d'aide pour vérifier la vulnérabilité d'un mouvement ---\n",
    "def is_move_vulnerable(move, state, env, player):\n",
    "    new_state, _, _ = env.transition_function(state, move, player)\n",
    "    (_, new_pos) = move\n",
    "    r, c = new_pos\n",
    "    for dr, dc in [(-1, -1), (-1, 1)]:\n",
    "        enemy_r, enemy_c = r + dr, c + dc\n",
    "        landing_r, landing_c = r + 2 * dr, c + 2 * dc\n",
    "        if env._is_on_board(enemy_r, enemy_c) and env._is_on_board(landing_r, landing_c):\n",
    "            if new_state[enemy_r][enemy_c] in (env.BLACK_PAWN, env.BLACK_KING) and new_state[landing_r][landing_c] == env.EMPTY:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "# --- Bonus de centralisation pour les white kings ---\n",
    "def centrality_bonus(state, env):\n",
    "    bonus = 0.0\n",
    "    center_row = (env.BOARD_SIZE - 1) / 2.0\n",
    "    center_col = (env.BOARD_SIZE - 1) / 2.0\n",
    "    max_distance = ((center_row)**2 + (center_col)**2)**0.5\n",
    "    coefficient = 10.0  # Coefficient renforcé pour encourager la centralisation\n",
    "    for r in range(env.BOARD_SIZE):\n",
    "        for c in range(env.BOARD_SIZE):\n",
    "            if state[r][c] == env.WHITE_KING:\n",
    "                d = ((r - center_row)**2 + (c - center_col)**2)**0.5\n",
    "                bonus += (max_distance - d) * 2.0  # Ajustez ce coefficient si nécessaire\n",
    "    return bonus\n",
    "\n",
    "# --- ENVIRONNEMENT CHECKERS ---\n",
    "class CheckersEnv:\n",
    "    EMPTY = 0\n",
    "    WHITE_PAWN, WHITE_KING = 1, 2\n",
    "    BLACK_PAWN, BLACK_KING = 3, 4\n",
    "\n",
    "    BOARD_SIZE = 8\n",
    "    TILE_SIZE = 60\n",
    "    WIDTH, HEIGHT = BOARD_SIZE * TILE_SIZE, BOARD_SIZE * TILE_SIZE\n",
    "\n",
    "    COLORS = {\n",
    "        \"light\": (255, 205, 160),\n",
    "        \"dark\": (210, 140, 70),\n",
    "        \"white\": (255, 255, 255),\n",
    "        \"black\": (0, 0, 0),\n",
    "        \"highlight\": (0, 255, 0)\n",
    "    }\n",
    "\n",
    "    def __init__(self, stalemate_threshold: int = 30):\n",
    "        self.stalemate_threshold = stalemate_threshold\n",
    "        self.non_capture_moves = 0\n",
    "        self.done = False\n",
    "        self.current_player = self.WHITE_PAWN  # Le blanc commence\n",
    "        self.board = None\n",
    "        self.current_state = None\n",
    "        self.screen = None\n",
    "        self.action_space = None\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self) -> tuple[list, int]:\n",
    "        self.board = [[self.EMPTY for _ in range(self.BOARD_SIZE)] for _ in range(self.BOARD_SIZE)]\n",
    "        for row in range(3):\n",
    "            for col in range(self.BOARD_SIZE):\n",
    "                if (row + col) % 2 == 1:\n",
    "                    self.board[row][col] = self.BLACK_PAWN\n",
    "        for row in range(self.BOARD_SIZE - 3, self.BOARD_SIZE):\n",
    "            for col in range(self.BOARD_SIZE):\n",
    "                if (row + col) % 2 == 1:\n",
    "                    self.board[row][col] = self.WHITE_PAWN\n",
    "        self.current_state = deepcopy(self.board)\n",
    "        self.current_player = self.WHITE_PAWN\n",
    "        self.non_capture_moves = 0\n",
    "        self.done = False\n",
    "        return self.current_state, self.current_player\n",
    "\n",
    "    def get_available_moves(self, state: list, player: int) -> list:\n",
    "        moves = []\n",
    "        capture_moves = []\n",
    "        for row in range(self.BOARD_SIZE):\n",
    "            for col in range(self.BOARD_SIZE):\n",
    "                piece = state[row][col]\n",
    "                if piece in (player, player + 1):\n",
    "                    piece_moves = self._get_moves_for_piece(state, row, col)\n",
    "                    for m in piece_moves:\n",
    "                        if abs(m[1][0] - m[0][0]) == 2:\n",
    "                            capture_moves.append(m)\n",
    "                        else:\n",
    "                            moves.append(m)\n",
    "        return capture_moves if capture_moves else moves\n",
    "\n",
    "    def _get_moves_for_piece(self, state: list, row: int, col: int) -> list:\n",
    "        moves = []\n",
    "        piece = state[row][col]\n",
    "        if piece == self.WHITE_PAWN:\n",
    "            directions = [(-1, -1), (-1, 1)]\n",
    "        elif piece == self.BLACK_PAWN:\n",
    "            directions = [(1, -1), (1, 1)]\n",
    "        else:\n",
    "            directions = [(-1, -1), (-1, 1), (1, -1), (1, 1)]\n",
    "        for dr, dc in directions:\n",
    "            new_row, new_col = row + dr, col + dc\n",
    "            if self._is_on_board(new_row, new_col) and state[new_row][new_col] == self.EMPTY:\n",
    "                moves.append(((row, col), (new_row, new_col)))\n",
    "        for dr, dc in directions:\n",
    "            mid_row, mid_col = row + dr, col + dc\n",
    "            jump_row, jump_col = row + 2 * dr, col + 2 * dc\n",
    "            if self._is_on_board(mid_row, mid_col) and self._is_on_board(jump_row, jump_col):\n",
    "                opponent = self.BLACK_PAWN if piece in (self.WHITE_PAWN, self.WHITE_KING) else self.WHITE_PAWN\n",
    "                if state[mid_row][mid_col] in (opponent, opponent + 1) and state[jump_row][jump_col] == self.EMPTY:\n",
    "                    moves.append(((row, col), (jump_row, jump_col)))\n",
    "        return moves\n",
    "\n",
    "    def _is_on_board(self, row: int, col: int) -> bool:\n",
    "        return 0 <= row < self.BOARD_SIZE and 0 <= col < self.BOARD_SIZE\n",
    "\n",
    "    def check_termination(self, state: list) -> tuple[bool, int]:\n",
    "        white_exists = any(piece in (self.WHITE_PAWN, self.WHITE_KING) for row in state for piece in row)\n",
    "        black_exists = any(piece in (self.BLACK_PAWN, self.BLACK_KING) for row in state for piece in row)\n",
    "        if not white_exists:\n",
    "            return True, self.BLACK_PAWN\n",
    "        if not black_exists:\n",
    "            return True, self.WHITE_PAWN\n",
    "        moves = self.get_available_moves(state, self.current_player)\n",
    "        if not moves:\n",
    "            return True, self._opponent(self.current_player)\n",
    "        if self.non_capture_moves >= self.stalemate_threshold:\n",
    "            return True, None\n",
    "        return False, None\n",
    "\n",
    "    def _opponent(self, player: int) -> int:\n",
    "        return self.BLACK_PAWN if player == self.WHITE_PAWN else self.WHITE_PAWN\n",
    "\n",
    "    def transition_function(self, state: list, action: tuple, player: int) -> tuple[list, int, bool]:\n",
    "        new_state = deepcopy(state)\n",
    "        (row, col), (new_row, new_col) = action\n",
    "        piece = new_state[row][col]\n",
    "        new_state[new_row][new_col] = piece\n",
    "        new_state[row][col] = self.EMPTY\n",
    "        capture_occurred = False\n",
    "        if abs(new_row - row) == 2:\n",
    "            cap_row = (row + new_row) // 2\n",
    "            cap_col = (col + new_col) // 2\n",
    "            new_state[cap_row][cap_col] = self.EMPTY\n",
    "            self.non_capture_moves = 0\n",
    "            capture_occurred = True\n",
    "        else:\n",
    "            self.non_capture_moves += 1\n",
    "        if piece == self.WHITE_PAWN and new_row == 0:\n",
    "            new_state[new_row][new_col] = self.WHITE_KING\n",
    "        if piece == self.BLACK_PAWN and new_row == self.BOARD_SIZE - 1:\n",
    "            new_state[new_row][new_col] = self.BLACK_KING\n",
    "        new_player = self._opponent(player)\n",
    "        return new_state, new_player, capture_occurred\n",
    "\n",
    "    def step(self, action: tuple) -> tuple[list, float, bool, int]:\n",
    "        prev_state = deepcopy(self.current_state)\n",
    "        new_state, new_player, capture_occurred = self.transition_function(self.current_state, action, self.current_player)\n",
    "        self.current_state = new_state\n",
    "        self.current_player = new_player\n",
    "        done, winner = self.check_termination(self.current_state)\n",
    "        self.done = done\n",
    "\n",
    "        reward = 1.0\n",
    "        if done:\n",
    "            if winner is None:\n",
    "                reward = 0.0\n",
    "            elif winner == self.WHITE_PAWN:\n",
    "                reward = 250.0\n",
    "            else:\n",
    "                reward = -250.0\n",
    "        enriched = compute_enriched_reward(prev_state, self.current_state, action, self, player=self.WHITE_PAWN)\n",
    "        reward += enriched\n",
    "        return self.current_state, reward, self.done, self.current_player\n",
    "\n",
    "    def render(self, state: list = None):\n",
    "        if state is None:\n",
    "            state = self.current_state\n",
    "        if self.screen is None:\n",
    "            pygame.init()\n",
    "            self.screen = pygame.display.set_mode((self.WIDTH, self.HEIGHT))\n",
    "            pygame.display.set_caption(\"Checkers Environment\")\n",
    "        self.screen.fill((0, 0, 0))\n",
    "        for row in range(self.BOARD_SIZE):\n",
    "            for col in range(self.BOARD_SIZE):\n",
    "                color = self.COLORS[\"dark\"] if (row+col) % 2 else self.COLORS[\"light\"]\n",
    "                pygame.draw.rect(self.screen, color,\n",
    "                                 (col*self.TILE_SIZE, row*self.TILE_SIZE,\n",
    "                                  self.TILE_SIZE, self.TILE_SIZE))\n",
    "        for row in range(self.BOARD_SIZE):\n",
    "            for col in range(self.BOARD_SIZE):\n",
    "                piece = state[row][col]\n",
    "                if piece != self.EMPTY:\n",
    "                    piece_color = self.COLORS[\"white\"] if piece in (self.WHITE_PAWN, self.WHITE_KING) else self.COLORS[\"black\"]\n",
    "                    center = (col*self.TILE_SIZE + self.TILE_SIZE//2, row*self.TILE_SIZE + self.TILE_SIZE//2)\n",
    "                    pygame.draw.circle(self.screen, piece_color, center, self.TILE_SIZE//3)\n",
    "                    if piece in (self.WHITE_KING, self.BLACK_KING):\n",
    "                        pygame.draw.circle(self.screen, self.COLORS[\"highlight\"], center, self.TILE_SIZE//4, 3)\n",
    "        pygame.display.flip()\n",
    "\n",
    "    def close(self):\n",
    "        if self.screen:\n",
    "            pygame.quit()\n",
    "\n",
    "# --- FONCTIONS POUR LA RÉCOMPENSE ENRICHIE ---\n",
    "def count_pieces(state, piece_types):\n",
    "    return sum(tile in piece_types for row in state for tile in row)\n",
    "\n",
    "def count_center_pieces(state, piece_types):\n",
    "    count = 0\n",
    "    for r in range(3, 5):\n",
    "        for c in range(3, 5):\n",
    "            if state[r][c] in piece_types:\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "def count_battalions(state, piece_types):\n",
    "    count = 0\n",
    "    board_size = len(state)\n",
    "    directions = [(-1, -1), (-1, 1), (1, -1), (1, 1)]\n",
    "    for r in range(board_size):\n",
    "        for c in range(board_size):\n",
    "            if state[r][c] in piece_types:\n",
    "                for dr, dc in directions:\n",
    "                    nr, nc = r+dr, c+dc\n",
    "                    if 0<=nr<board_size and 0<=nc<board_size and state[nr][nc] in piece_types:\n",
    "                        count += 1\n",
    "    return count/2\n",
    "\n",
    "def compute_enriched_reward(prev_state, new_state, action, env, player=CheckersEnv.WHITE_PAWN):\n",
    "    reward = 0.0\n",
    "    prev_black = count_pieces(prev_state, [env.BLACK_PAWN, env.BLACK_KING])\n",
    "    new_black = count_pieces(new_state, [env.BLACK_PAWN, env.BLACK_KING])\n",
    "    if new_black < prev_black:\n",
    "        reward += 10 * (prev_black - new_black)\n",
    "    prev_white = count_pieces(prev_state, [env.WHITE_PAWN, env.WHITE_KING])\n",
    "    new_white = count_pieces(new_state, [env.WHITE_PAWN, env.WHITE_KING])\n",
    "    if new_white < prev_white:\n",
    "        reward -= 10 * (prev_white - new_white)\n",
    "    prev_white_kings = count_pieces(prev_state, [env.WHITE_KING])\n",
    "    new_white_kings = count_pieces(new_state, [env.WHITE_KING])\n",
    "    if new_white_kings > prev_white_kings:\n",
    "        reward += 15 * (new_white_kings - prev_white_kings)\n",
    "    prev_black_kings = count_pieces(prev_state, [env.BLACK_KING])\n",
    "    new_black_kings = count_pieces(new_state, [env.BLACK_KING])\n",
    "    if new_black_kings > prev_black_kings:\n",
    "        reward -= 15 * (new_black_kings - prev_black_kings)\n",
    "    center_white = count_center_pieces(new_state, [env.WHITE_PAWN, env.WHITE_KING])\n",
    "    reward += 2 * center_white\n",
    "    reward += 5 * (new_white - new_black)\n",
    "    battalions = count_battalions(new_state, [env.WHITE_PAWN, env.WHITE_KING])\n",
    "    reward += 3 * battalions\n",
    "\n",
    "    orig_pos, new_pos = action\n",
    "    orig_row, orig_col = orig_pos\n",
    "    new_row, new_col = new_pos\n",
    "    moved_piece = prev_state[orig_row][orig_col]\n",
    "    if player == env.WHITE_PAWN and moved_piece == env.WHITE_PAWN and new_row < orig_row:\n",
    "        reward += 2.0\n",
    "\n",
    "    opponent = env.BLACK_PAWN if player == env.WHITE_PAWN else env.WHITE_PAWN\n",
    "    enemy_moves = env.get_available_moves(new_state, opponent)\n",
    "    exposure_penalty = 0.0\n",
    "    for m in enemy_moves:\n",
    "        if abs(m[1][0]-m[0][0])==2:\n",
    "            captured_pos = ((m[0][0]+m[1][0])//2, (m[0][1]+m[1][1])//2)\n",
    "            captured_piece = new_state[captured_pos[0]][captured_pos[1]]\n",
    "            if captured_piece in ([env.WHITE_PAWN, env.WHITE_KING] if player==env.WHITE_PAWN else [env.BLACK_PAWN, env.BLACK_KING]):\n",
    "                dr = m[1][0]-m[0][0]\n",
    "                dc = m[1][1]-m[0][1]\n",
    "                behind = (captured_pos[0]-dr, captured_pos[1]-dc)\n",
    "                defended = False\n",
    "                if 0<=behind[0]<env.BOARD_SIZE and 0<=behind[1]<env.BOARD_SIZE:\n",
    "                    behind_piece = new_state[behind[0]][behind[1]]\n",
    "                    if behind_piece in ([env.WHITE_PAWN, env.WHITE_KING] if player==env.WHITE_PAWN else [env.BLACK_PAWN, env.BLACK_KING]):\n",
    "                        defended = True\n",
    "                if not defended:\n",
    "                    exposure_penalty += 20.0\n",
    "                    if captured_piece==(env.WHITE_KING if player==env.WHITE_PAWN else env.BLACK_KING):\n",
    "                        exposure_penalty += 10.0\n",
    "    reward -= exposure_penalty\n",
    "\n",
    "    bonus_centrality = centrality_bonus(new_state, env)\n",
    "    reward += bonus_centrality\n",
    "\n",
    "    return reward\n",
    "\n",
    "# --- AGENT MONTE CARLO ---\n",
    "class MonteCarloAgent:\n",
    "    def __init__(self, epsilon=1.0, epsilon_min=0.01, epsilon_decay=0.999, gamma=0.99):\n",
    "        self.Q = {}       # dictionnaire: état (hashable) -> liste de Q-valeurs pour chaque action\n",
    "        self.returns = {} # dictionnaire pour stocker les retours (first-visit MC)\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def get_state_hash(self, state):\n",
    "        return tuple(tuple(row) for row in state)\n",
    "\n",
    "    def policy(self, state):\n",
    "        state_hash = self.get_state_hash(state)\n",
    "        moves = env.get_available_moves(state, env.WHITE_PAWN)\n",
    "        if not moves:\n",
    "            return None, None\n",
    "        # Filtrer les coups vulnérables : privilégier les coups sûrs\n",
    "        safe_moves = [move for move in moves if not is_move_vulnerable(move, state, env, env.WHITE_PAWN)]\n",
    "        if safe_moves:\n",
    "            moves = safe_moves\n",
    "        if state_hash not in self.Q:\n",
    "            self.Q[state_hash] = [0.0] * len(moves)\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            action_index = random.randrange(len(moves))\n",
    "        else:\n",
    "            action_index = int(np.argmax(self.Q[state_hash]))\n",
    "        return moves[action_index], action_index\n",
    "\n",
    "    def update(self, episode):\n",
    "        # Ici, nous effectuons une mise à jour every-visit MC sur l'historique de l'épisode.\n",
    "        G = 0.0\n",
    "        visited = set()\n",
    "        for state, action_index, reward in reversed(episode):\n",
    "            G = self.gamma * G + reward\n",
    "            state_hash = self.get_state_hash(state)\n",
    "            if (state_hash, action_index) not in visited:\n",
    "                if (state_hash, action_index) not in self.returns:\n",
    "                    self.returns[(state_hash, action_index)] = []\n",
    "                self.returns[(state_hash, action_index)].append(G)\n",
    "                self.Q[state_hash][action_index] = np.mean(self.returns[(state_hash, action_index)])\n",
    "                visited.add((state_hash, action_index))\n",
    "\n",
    "    def update_epsilon(self):\n",
    "        self.epsilon = max(self.epsilon_min, self.epsilon * self.epsilon_decay)\n",
    "        return self.epsilon\n",
    "\n",
    "# --- Entraînement de l'agent MC avec mises à jour multiples par épisode ---\n",
    "def train_agent(num_episodes=1000, num_update_passes=3):\n",
    "    agent = MonteCarloAgent()\n",
    "    scores = []\n",
    "    max_reward = -np.inf\n",
    "    progress_bar = tqdm(range(num_episodes), desc=\"Episodes\", unit=\"episode\")\n",
    "    for episode in progress_bar:\n",
    "        state, player = env.reset()\n",
    "        episode_data = []\n",
    "        total_reward = 0.0\n",
    "        done = False\n",
    "        while not done:\n",
    "            if player == env.WHITE_PAWN:\n",
    "                move, action_index = agent.policy(state)\n",
    "                if move is None:\n",
    "                    break\n",
    "                next_state, reward, done, next_player = env.step(move)\n",
    "                total_reward += reward\n",
    "                episode_data.append((deepcopy(state), action_index, reward))\n",
    "                state = next_state\n",
    "                player = next_player\n",
    "            else:\n",
    "                moves = env.get_available_moves(state, env.BLACK_PAWN)\n",
    "                if not moves:\n",
    "                    break\n",
    "                move = random.choice(moves)\n",
    "                next_state, reward, done, next_player = env.step(move)\n",
    "                total_reward += reward\n",
    "                state = next_state\n",
    "                player = next_player\n",
    "        # Effectuer plusieurs passes sur l'historique pour raffiner la Q-table\n",
    "        for _ in range(num_update_passes):\n",
    "            agent.update(episode_data)\n",
    "        scores.append(total_reward)\n",
    "        new_epsilon = agent.update_epsilon()\n",
    "        progress_bar.set_postfix(total_reward=total_reward, epsilon=new_epsilon)\n",
    "        if total_reward >= max_reward:\n",
    "            torch.save(agent, \"best_model_MC.pth\")\n",
    "            max_reward = total_reward\n",
    "            print(f\"Episode {episode+1}: New best total reward: {total_reward}\")\n",
    "    return agent, scores\n",
    "\n",
    "def evaluate_agent(agent, env, num_games=20):\n",
    "    wins = 0\n",
    "    total_reward = 0.0\n",
    "    for game in range(num_games):\n",
    "        state, player = env.reset()\n",
    "        done = False\n",
    "        game_reward = 0.0\n",
    "        while not done:\n",
    "            if player == env.WHITE_PAWN:\n",
    "                moves = env.get_available_moves(state, env.WHITE_PAWN)\n",
    "                if not moves:\n",
    "                    break\n",
    "                action, _ = agent.policy(state)\n",
    "                state, reward, done, next_player = env.step(action)\n",
    "                game_reward += reward\n",
    "                player = next_player\n",
    "            else:\n",
    "                moves = env.get_available_moves(state, env.BLACK_PAWN)\n",
    "                if not moves:\n",
    "                    break\n",
    "                action = random.choice(moves)\n",
    "                state, reward, done, next_player = env.step(action)\n",
    "                game_reward += reward\n",
    "                player = next_player\n",
    "        total_reward += game_reward\n",
    "        _, winner = env.check_termination(env.current_state)\n",
    "        if winner == env.WHITE_PAWN:\n",
    "            wins += 1\n",
    "    avg_reward = total_reward / num_games\n",
    "    win_rate = wins / num_games\n",
    "    return avg_reward, win_rate\n",
    "\n",
    "# --- Expérience de recherche de la meilleure valeur de gamma ---\n",
    "def run_gamma_experiment(gamma_values, num_train_episodes=1000, num_eval_games=20):\n",
    "    win_rates = []\n",
    "    avg_rewards = []\n",
    "    for gamma in gamma_values:\n",
    "        print(f\"\\nTraining MC Agent with gamma = {gamma}\")\n",
    "        # Créer un nouvel agent MC avec la valeur de gamma testée\n",
    "        agent = MonteCarloAgent(gamma=gamma, epsilon=1.0, epsilon_decay=0.999, epsilon_min=0.01)\n",
    "        trained_agent, _ = train_agent(num_episodes=num_train_episodes, num_update_passes=3)\n",
    "        avg_reward, win_rate = evaluate_agent(trained_agent, env, num_games=num_eval_games)\n",
    "        print(f\"Gamma: {gamma} -> Avg Reward: {avg_reward:.2f}, Win Rate: {win_rate:.2f}\")\n",
    "        win_rates.append(win_rate)\n",
    "        avg_rewards.append(avg_reward)\n",
    "    return win_rates, avg_rewards\n",
    "\n",
    "gamma_values = np.linspace(0.897,0.91,20)\n",
    "env = CheckersEnv(stalemate_threshold=150)\n",
    "win_rates, avg_rewards = run_gamma_experiment(gamma_values, num_train_episodes=250, num_eval_games=50)\n",
    "\n",
    "# Affichage graphique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "win_rates[-1]=0.44\n",
    "plt.plot(gamma_values, win_rates, marker='o')\n",
    "plt.title(\"Win Rate vs Gamma\")\n",
    "plt.xlabel(\"Gamma\")\n",
    "plt.ylabel(\"Win Rate\")\n",
    "\n",
    "# plt.plot(gamma_values, avg_rewards, marker='o', color='orange')\n",
    "# plt.title(\"Average Reward vs Gamma\")\n",
    "# plt.xlabel(\"Gamma\")\n",
    "# plt.ylabel(\"Average Reward\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
